import torch
import cv2
import numpy as np
from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor
from PIL import Image
import os
import warnings
import logging

# ==========================================
# [ì„¤ì •] ê²½ê³  ë¬´ì‹œ
# ==========================================
warnings.filterwarnings("ignore") 
logging.getLogger("transformers").setLevel(logging.ERROR)

# ==========================================
# 1. ì„¤ì • (íŒŒì¼ ê²½ë¡œ í™•ì¸ í•„ìˆ˜)
# ==========================================
MODEL_NAME = "nvidia/mit-b0" 
WEIGHT_PATH = r"runs\seg\PA\PA_MIOU.pth" 
IMAGE_PATH = r"C:\Users\sega0\Desktop\chytonpide-ai\predict_image\test4.jpg"

# â˜…â˜…â˜… í•µì‹¬ ìˆ˜ì •: í´ë˜ìŠ¤ ê°œìˆ˜ë¥¼ 2ê°œ(ë°°ê²½, ì)ë¡œ ê³ ì • â˜…â˜…â˜…
NUM_CLASSES = 2 

# ==========================================
# 2. ìƒìœ¡ ë‹¨ê³„ íŒë³„ ë¡œì§
# ==========================================
def determine_stage(leaf_count):
    stage_name = "ì•Œ ìˆ˜ ì—†ìŒ"
    msg = ""
    if leaf_count <= 2:
        stage_name = "ğŸŒ± ë–¡ì ë‹¨ê³„"
        msg = "ë–¡ìë§Œ ì¡´ì¬í•˜ê±°ë‚˜, ë³¸ì—½ì´ ë‚˜ì˜¤ê¸° ì§ì „ì…ë‹ˆë‹¤."
    elif 3 <= leaf_count <= 4:
        stage_name = "ğŸŒ¿ ë³¸ì—½ 2ë§¤"
        msg = "ë³¸ì—½ì´ 1ìŒ(2ì¥) ì „ê°œëœ ìƒíƒœì…ë‹ˆë‹¤."
    elif 5 <= leaf_count <= 8:
        stage_name = "ğŸŒ¿ ë³¸ì—½ 4ë§¤ ~ 8ë§¤"
        msg = "ë³¸ì—½ì´ 2ìŒì—ì„œ 4ìŒê¹Œì§€ í™œë°œíˆ ìë¼ëŠ” ì¤‘ì…ë‹ˆë‹¤."
    elif 9 <= leaf_count <= 10:
        stage_name = "ğŸŒ¿ ë³¸ì—½ 8ë§¤ ~ 10ë§¤"
        msg = "ë³¸ì—½ ì„±ì¥ì´ ê±°ì˜ ì™„ë£Œë˜ì–´ ê°€ë©°, ê³§ ë¶„ì§€ê°€ ì˜ˆìƒë©ë‹ˆë‹¤."
    else:
        stage_name = "ğŸŒ³ ë¶„ì§€ ë°œìƒ"
        msg = "ìì´ 10ë§¤ ì´ìƒì´ë©°, ê³ê°€ì§€(ë¶„ì§€)ê°€ ë°œë‹¬í•˜ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤."
    return stage_name, msg

# ==========================================
# 3. ëª¨ë¸ ì¶”ë¡  ì—”ì§„
# ==========================================
def run_inference(image_path, weight_path):
    if not os.path.exists(image_path):
        print(f"âŒ ì—ëŸ¬: ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ -> {image_path}")
        return None, None

    print(f"â–¶ AI ë¶„ì„ ì‹œì‘... ({os.path.basename(image_path)})")
    
    try:
        # [ìˆ˜ì •] num_labels=NUM_CLASSES (2)ë¥¼ ë°˜ë“œì‹œ ë„£ì–´ì¤˜ì•¼ ê°€ì¤‘ì¹˜ê°€ ë§ìŠµë‹ˆë‹¤.
        id2label = {0: "background", 1: "leaf"}
        label2id = {"background": 0, "leaf": 1}
        
        model = SegformerForSemanticSegmentation.from_pretrained(
            MODEL_NAME, 
            num_labels=NUM_CLASSES, 
            id2label=id2label,
            label2id=label2id,
            ignore_mismatched_sizes=True
        )
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None, None

    try:
        checkpoint = torch.load(weight_path, map_location="cpu")
        # ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹œë„
        if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
            model.load_state_dict(checkpoint['state_dict'], strict=False)
        else:
             model.load_state_dict(checkpoint, strict=False)
        print("â–¶ ê°€ì¤‘ì¹˜ ì ìš© ì„±ê³µ!")
    except Exception as e:
        print(f"âŒ ê°€ì¤‘ì¹˜ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None

    model.eval()
    image_processor = SegformerImageProcessor.from_pretrained(MODEL_NAME)

    # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§• (ì†ë„ í–¥ìƒ & ë©”ëª¨ë¦¬ ì ˆì•½)
    raw_image = Image.open(image_path).convert("RGB")
    image = raw_image.resize((640, 640)) 

    inputs = image_processor(images=image, return_tensors="pt")

    with torch.no_grad():
        outputs = model(**inputs)
        
    logits = outputs.logits
    upsampled_logits = torch.nn.functional.interpolate(
        logits,
        size=image.size[::-1], 
        mode="bilinear",
        align_corners=False,
    )
    
    pred_mask = upsampled_logits.argmax(dim=1)[0].numpy().astype(np.uint8)
    return pred_mask, np.array(image)

# ==========================================
# 4. ê²°ê³¼ ë¶„ì„ ë° ì €ì¥
# ==========================================
def analyze_and_show(mask, original_image):
    if mask is None: return

    # ë§ˆìŠ¤í¬ì—ì„œ ì(1) ë¶€ë¶„ë§Œ ì¶”ì¶œ
    leaf_mask = (mask == 1).astype(np.uint8) * 255
    
    # ì ê°œìˆ˜ ì„¸ê¸°
    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(leaf_mask, connectivity=8)
    leaf_count = num_labels - 1 

    current_stage, message = determine_stage(leaf_count)

    print("\n" + "="*40)
    print(f"ğŸŒ± [AI ìŠ¤ë§ˆíŠ¸íŒœ ë¶„ì„ ê²°ê³¼]")
    print(f"="*40)
    print(f"ğŸ“¸ ì ê°œìˆ˜      : {leaf_count} ì¥")
    print(f"ğŸ† í˜„ì¬ ë‹¨ê³„    : {current_stage}")
    print(f"ğŸ’¬ ìƒì„¸ ì„¤ëª…    : {message}")
    print("="*40)

    # ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„± (ì´ˆë¡ìƒ‰ ë§ˆìŠ¤í‚¹)
    color_mask = np.zeros_like(original_image)
    color_mask[mask == 1] = [0, 255, 0] 
    
    result_img = cv2.addWeighted(original_image, 0.7, color_mask, 0.3, 0)
    
    # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
    cv2.putText(result_img, f"Stage: {current_stage.split(' ')[-1]}", (10, 30), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
    cv2.putText(result_img, f"Leaf Count: {leaf_count}", (10, 60), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)

    # íŒŒì¼ë¡œ ì €ì¥ (ì—ëŸ¬ ë°©ì§€)
    save_filename = "result_analysis.jpg"
    final_img_bgr = cv2.cvtColor(result_img, cv2.COLOR_RGB2BGR)
    cv2.imwrite(save_filename, final_img_bgr)
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì´ë¯¸ì§€ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {os.path.abspath(save_filename)}")

if __name__ == "__main__":
    mask_result, img_result = run_inference(IMAGE_PATH, WEIGHT_PATH)
    analyze_and_show(mask_result, img_result)