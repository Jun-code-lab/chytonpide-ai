import cv2
import numpy as np
import io
import logging
import os
import torch
import warnings
import json  # â˜… JSON ì €ì¥ì„ ìœ„í•´ ì¶”ê°€
import tempfile
import time  # â˜… ì‹œê°„ ì¸¡ì •ì„ ìœ„í•´ ì¶”ê°€
from PIL import Image, ImageOps
from ultralytics import YOLO

# â˜… Hugging Face API í´ë¼ì´ì–¸íŠ¸
from gradio_client import Client, handle_file

# ==========================================
# [ì„¤ì •] ë¡œê·¸ ë° ê²½ê³  ì„¤ì •
# ==========================================
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
warnings.filterwarnings("ignore")

# ==========================================
# [ì„¤ì •] ëª¨ë¸ ë° íŒŒì¼ ê²½ë¡œ
# ==========================================
# 1. YOLO ëª¨ë¸ (ë¡œì»¬ ì‹¤í–‰)
DET_MODEL_PATH = r"runs\detect\det_exp1\weights\best.pt"
CLS_MODEL_PATH = r"runs\classify\test1\weights\best.pt"

# 2. SAM 3 API ì„¤ì •
SAM3_API_URL = "akhaliq/sam3"  # Hugging Face Space ID
# ìˆ˜ì •: 'basil leaves' -> 'leaf' (ë” ì¼ë°˜ì ì¸ ë‹¨ì–´ê°€ ì¸ì‹ë¥ ì´ ë†’ìŒ)
SAM_TEXT_PROMPT = "leaf" 

# 3. í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œ
TEST_IMAGE_PATH = r"C:\Users\sega0\Desktop\chytonpide-ai\predict_image\test6.jpg"

# 4. ê¸°íƒ€ ì„¤ì •
SCALE_REAL_DIAMETER_MM = 16.0
GREEN_HSV_LOWER = [35, 40, 40]
GREEN_HSV_UPPER = [85, 255, 255]


class HybridBasilAnalyzer:
    """
    [í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ê¸°]
    - ë¡œì»¬: YOLO (íƒì§€, ë¶„ë¥˜, PLA)
    - í´ë¼ìš°ë“œ API: SAM 3 (ì ì •ë°€ ë¶„í• )
    """

    def __init__(self):
        logger.info("ğŸ¤– AI ëª¨ë¸ ë¡œë”© ì‹œì‘...")
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        try:
            # 1. YOLO ëª¨ë¸ ë¡œë”© (ë¡œì»¬)
            self.det_model = YOLO(DET_MODEL_PATH)
            self.cls_model = YOLO(CLS_MODEL_PATH)
            logger.info("âœ… YOLO ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

            # 2. SAM 3 API í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
            logger.info(f"â˜ï¸ SAM 3 API ì„œë²„ ì—°ê²° ì¤‘... ({SAM3_API_URL})")
            self.sam_client = Client(SAM3_API_URL)
            logger.info("âœ… API ì„œë²„ ì—°ê²° ì„±ê³µ!")

        except Exception as e:
            logger.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    def _determine_stage(self, leaf_count):
        """ì ê°œìˆ˜ì— ë”°ë¥¸ ë‹¨ê³„ íŒë³„"""
        if leaf_count <= 2:
            return "ğŸŒ± ë–¡ì ë‹¨ê³„", "ë–¡ìë§Œ ì¡´ì¬í•˜ê±°ë‚˜, ë³¸ì—½ì´ ë‚˜ì˜¤ê¸° ì§ì „ì…ë‹ˆë‹¤."
        elif 3 <= leaf_count <= 4:
            return "ğŸŒ¿ ë³¸ì—½ 2ë§¤", "ë³¸ì—½ì´ 1ìŒ(2ì¥) ì „ê°œëœ ìƒíƒœì…ë‹ˆë‹¤."
        elif 5 <= leaf_count <= 8:
            return "ğŸŒ¿ ë³¸ì—½ 4ë§¤ ~ 8ë§¤", "ë³¸ì—½ì´ 2ìŒì—ì„œ 4ìŒê¹Œì§€ í™œë°œíˆ ìë¼ëŠ” ì¤‘ì…ë‹ˆë‹¤."
        elif 9 <= leaf_count <= 10:
            return "ğŸŒ¿ ë³¸ì—½ 8ë§¤ ~ 10ë§¤", "ë³¸ì—½ ì„±ì¥ì´ ê±°ì˜ ì™„ë£Œë˜ì–´ ê°€ë©°, ê³§ ë¶„ì§€ê°€ ì˜ˆìƒë©ë‹ˆë‹¤."
        else:
            return "ğŸŒ³ ë¶„ì§€ ë°œìƒ", "ìì´ 10ë§¤ ì´ìƒì´ë©°, ê³ê°€ì§€(ë¶„ì§€)ê°€ ë°œë‹¬í•˜ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤."

    def _call_sam3_api(self, basil_crop_pil):
        """
        ë°”ì§ˆ Crop ì´ë¯¸ì§€ë¥¼ APIë¡œ ë³´ë‚´ ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì•„ì˜´
        """
        temp_path = "temp_crop_for_api.jpg"
        
        try:
            # 1. API ì „ì†¡ì„ ìœ„í•´ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            basil_crop_pil.save(temp_path)
            
            logger.info(f"ğŸš€ API ìš”ì²­ ì „ì†¡ (Prompt: '{SAM_TEXT_PROMPT}')... ëŒ€ê¸° ì¤‘...")
            
            # 2. API í˜¸ì¶œ (ê°ë„ ì¡°ì ˆ)
            result = self.sam_client.predict(
                image=handle_file(temp_path),
                text=SAM_TEXT_PROMPT,
                threshold=0.4,      
                mask_threshold=0.4,
                api_name="/segment"
            )
            
            logger.info(f"ğŸ“¡ API Raw Result: {result}")

            # 3. ê²°ê³¼ íŒŒì‹± (ì—…ë°ì´íŠ¸ëœ ë¡œì§)
            # êµ¬ì¡°: ({'image': '...', 'annotations': [{'image': 'path/to/mask.png', 'label': ...}, ...]}, "Message")
            
            combined_mask = None
            leaf_count = 0
            
            # íŠœí”Œ/ë¦¬ìŠ¤íŠ¸ì´ê³  ì²« ë²ˆì§¸ ìš”ì†Œê°€ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° (ì •ìƒ ì‘ë‹µ)
            if isinstance(result, (tuple, list)) and len(result) > 0 and isinstance(result[0], dict):
                data = result[0]
                
                # 'annotations' í‚¤ í™•ì¸
                if 'annotations' in data and isinstance(data['annotations'], list):
                    annotations = data['annotations']
                    leaf_count = len(annotations)
                    logger.info(f"âœ… APIì—ì„œ {leaf_count}ê°œì˜ ì(annotations)ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
                    
                    # ê° ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ë¡œë“œ ë° ë³‘í•©
                    for i, item in enumerate(annotations):
                        mask_path = item.get('image')
                        if mask_path and os.path.exists(mask_path):
                            # ë§ˆìŠ¤í¬ ë¡œë“œ (í‘ë°±)
                            part_mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
                            
                            if part_mask is not None:
                                # ìº”ë²„ìŠ¤ ì´ˆê¸°í™” (ì²« ë§ˆìŠ¤í¬ í¬ê¸°ì— ë§ì¶¤)
                                if combined_mask is None:
                                    combined_mask = np.zeros_like(part_mask)
                                
                                # í¬ê¸°ê°€ ë‹¤ë¥¼ ê²½ìš° ì•ˆì „ì¥ì¹˜ (Resize)
                                if part_mask.shape != combined_mask.shape:
                                    part_mask = cv2.resize(part_mask, (combined_mask.shape[1], combined_mask.shape[0]), interpolation=cv2.INTER_NEAREST)
                                    
                                # ë§ˆìŠ¤í¬ í•©ì¹˜ê¸° (OR ì—°ì‚°)
                                combined_mask = np.maximum(combined_mask, part_mask)
            
            # ë§Œì•½ ìœ„ êµ¬ì¡°ê°€ ì•„ë‹ˆë¼ë©´ (ì˜ˆì „ ë°©ì‹ Fallback)
            elif isinstance(result, (tuple, list)) and len(result) > 1 and isinstance(result[1], str) and os.path.exists(result[1]):
                mask_path = result[1]
                logger.info("ğŸ‘‰ Fallback: ë‹¨ì¼ ë§ˆìŠ¤í¬ íŒŒì¼ ê²½ë¡œ ì‚¬ìš©")
                mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
                if mask_img is not None:
                    _, combined_mask = cv2.threshold(mask_img, 127, 255, cv2.THRESH_BINARY)
                    num_labels, _, _, _ = cv2.connectedComponentsWithStats(combined_mask, connectivity=8)
                    leaf_count = num_labels - 1

            if combined_mask is None:
                logger.warning(f"âš ï¸ ìœ íš¨í•œ ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (Result: {result})")
                return None

            # 4. ê²°ê³¼ ì •ë¦¬
            stage_name, message = self._determine_stage(leaf_count)
            
            return {
                "leaf_count": leaf_count,
                "stage": stage_name,
                "message": message,
                "mask": combined_mask # ì‹œê°í™”ìš©
            }

        except Exception as e:
            logger.error(f"âŒ API í†µì‹  ì¤‘ ì˜¤ë¥˜: {e}")
            return None
        finally:
            if os.path.exists(temp_path):
                os.remove(temp_path)

    def _calculate_pla(self, basil_crop_bgr, mm_per_pixel):
        """ê¸°ì¡´ PLA ê³„ì‚°"""
        try:
            basil_hsv = cv2.cvtColor(basil_crop_bgr, cv2.COLOR_BGR2HSV)
            lower = np.array(GREEN_HSV_LOWER, dtype=np.uint8)
            upper = np.array(GREEN_HSV_UPPER, dtype=np.uint8)
            mask = cv2.inRange(basil_hsv, lower, upper)
            kernel = np.ones((3, 3), np.uint8)
            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
            pixels = cv2.countNonZero(mask)
            area = pixels * (mm_per_pixel ** 2)
            return {"pla_mm2": round(area, 2), "green_pixels": pixels}
        except:
            return None

    def process_file(self, image_path):
        if not os.path.exists(image_path):
            return
        with open(image_path, "rb") as f:
            return self.process(f.read())

    def process(self, image_bytes):
        # ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ì‹œê°„ ì¸¡ì •
        total_start_time = time.time()
        
        try:
            # 1. ì´ë¯¸ì§€ ë¡œë“œ
            origin_img_pil = Image.open(io.BytesIO(image_bytes))
            origin_img_pil = ImageOps.exif_transpose(origin_img_pil).convert("RGB")
            origin_img_bgr = cv2.cvtColor(np.array(origin_img_pil), cv2.COLOR_RGB2BGR)

            # 2. YOLO íƒì§€ (Crop & Scale) - ë¡œì»¬ ìˆ˜í–‰
            yolo_start_time = time.time()
            results = self.det_model(origin_img_pil, conf=0.15, verbose=False)
            yolo_end_time = time.time()
            yolo_duration = yolo_end_time - yolo_start_time
            
            mm_per_pixel = 0.1
            basil_crop_pil = None
            basil_crop_bgr = None
            
            if len(results) > 0:
                boxes = results[0].boxes
                cls_ids = boxes.cls.cpu().numpy().astype(int)
                for i, cls_id in enumerate(cls_ids):
                    x1, y1, x2, y2 = map(int, boxes[i].xyxy[0])
                    
                    if cls_id == 1: # Scale
                        d = max(x2 - x1, y2 - y1)
                        mm_per_pixel = SCALE_REAL_DIAMETER_MM / d
                    
                    elif cls_id == 0: # Basil
                        basil_crop_bgr = origin_img_bgr[y1:y2, x1:x2]
                        basil_crop_pil = Image.fromarray(cv2.cvtColor(basil_crop_bgr, cv2.COLOR_BGR2RGB))
                        logger.info(f"ğŸŒ¿ ë°”ì§ˆ ë°œê²¬! í¬ê¸°: {basil_crop_pil.size}")

            if basil_crop_pil is None:
                return {"status": "error", "message": "ë°”ì§ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

            # 3. API í˜¸ì¶œ (ì‹œê°„ ì¸¡ì •)
            api_start_time = time.time()
            growth_info = self._call_sam3_api(basil_crop_pil)
            api_end_time = time.time()
            api_duration = api_end_time - api_start_time

            # 4. ê¸°íƒ€ ë¶„ì„ (PLA, Health)
            pla_result = self._calculate_pla(basil_crop_bgr, mm_per_pixel)
            
            cls_res = self.cls_model(basil_crop_pil, verbose=False)[0]
            health = cls_res.names[cls_res.probs.top1]
            conf = float(cls_res.probs.top1conf) * 100

            # 5. ì‹œê°í™” ì €ì¥
            self._save_visualization(basil_crop_bgr, growth_info)

            # 6. JSON ì €ì¥ì„ ìœ„í•´ mask ë°ì´í„°(numpy ë°°ì—´)ëŠ” ì œê±°
            growth_data_for_json = None
            if growth_info:
                growth_data_for_json = growth_info.copy()
                if 'mask' in growth_data_for_json:
                    del growth_data_for_json['mask']  # numpy ë°°ì—´ì€ JSON ì €ì¥ ë¶ˆê°€í•˜ë¯€ë¡œ ì œê±°

            # ì „ì²´ ì¢…ë£Œ ì‹œê°„ ì¸¡ì •
            total_end_time = time.time()
            total_duration = total_end_time - total_start_time
            
            # ë¡œê·¸ ì¶œë ¥
            logger.info(f"â±ï¸ ì‹¤í–‰ ì‹œê°„ - ì´ ì†Œìš”: {total_duration:.2f}ì´ˆ (YOLO: {yolo_duration:.2f}ì´ˆ, API: {api_duration:.2f}ì´ˆ)")

            return {
                "status": "success",
                "data": {
                    "health": {"status": health, "confidence": f"{conf:.2f}%"},
                    "pla": pla_result,
                    "growth": growth_data_for_json,
                    "execution_time": {
                        "total_seconds": round(total_duration, 2),
                        "yolo_seconds": round(yolo_duration, 2),
                        "api_seconds": round(api_duration, 2)
                    }
                }
            }

        except Exception as e:
            logger.error(f"ì˜¤ë¥˜: {e}", exc_info=True)
            return {"status": "error", "message": str(e)}

    def _save_visualization(self, crop_img, growth_info):
        """ê²°ê³¼ ì €ì¥"""
        try:
            if growth_info and growth_info.get('mask') is not None:
                mask = growth_info['mask']
                if mask.shape[:2] != crop_img.shape[:2]:
                    mask = cv2.resize(mask, (crop_img.shape[1], crop_img.shape[0]), interpolation=cv2.INTER_NEAREST)
                
                color_mask = np.zeros_like(crop_img)
                color_mask[mask > 0] = [0, 255, 0]
                overlay = cv2.addWeighted(crop_img, 0.7, color_mask, 0.3, 0)
                
                txt = f"{growth_info['stage']} (Leaves: {growth_info['leaf_count']})"
                cv2.putText(overlay, txt, (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
                
                cv2.imwrite("result_api_hybrid.jpg", overlay)
                logger.info("ğŸ’¾ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: result_api_hybrid.jpg")
        except:
            pass

if __name__ == "__main__":
    analyzer = HybridBasilAnalyzer()
    print(f"\nğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì‹œì‘: {TEST_IMAGE_PATH}")
    
    # ë¶„ì„ ì‹¤í–‰ ë° ê²°ê³¼ ë°›ê¸°
    final_result = analyzer.process_file(TEST_IMAGE_PATH)
    
    # ê²°ê³¼ ì²˜ë¦¬
    if final_result:
        # 1. JSON íŒŒì¼ë¡œ ì €ì¥
        json_filename = "result.json"
        try:
            with open(json_filename, "w", encoding="utf-8") as f:
                json.dump(final_result, f, ensure_ascii=False, indent=4)
            print(f"\nğŸ’¾ ê²°ê³¼ ë°ì´í„°(JSON) ì €ì¥ ì™„ë£Œ: {os.path.abspath(json_filename)}")
        except Exception as e:
            print(f"âŒ JSON ì €ì¥ ì‹¤íŒ¨: {e}")

        # 2. ì½˜ì†” ë¡œê·¸ì— ì¶œë ¥ (ë³µì‚¬í•´ì„œ ì“°ê¸° ì¢‹ê²Œ)
        print("\nğŸ“Š [ë¶„ì„ ê²°ê³¼ JSON ì¶œë ¥]")
        print("="*40)
        print(json.dumps(final_result, ensure_ascii=False, indent=4))
        print("="*40)
    else:
        print("âŒ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")