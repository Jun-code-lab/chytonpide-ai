import cv2
import numpy as np
import io
import logging
import os
import torch
import warnings
from PIL import Image, ImageOps
from ultralytics import YOLO
from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor

# ==========================================
# [ì„¤ì •] ë¡œê·¸ ë° ê²½ê³  ì„¤ì •
# ==========================================
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
warnings.filterwarnings("ignore")
logging.getLogger("transformers").setLevel(logging.ERROR)

# ==========================================
# [ì„¤ì •] ëª¨ë¸ ë° íŒŒì¼ ê²½ë¡œ (â˜…â˜… ìˆ˜ì • í•„ìš” â˜…â˜…)
# ==========================================
# 1. YOLO ëª¨ë¸ ê²½ë¡œ
DET_MODEL_PATH = r"runs\detect\det_exp1\weights\best.pt"        # íƒì§€ ëª¨ë¸ (ì—†ìœ¼ë©´ ìë™ ë‹¤ìš´ë¡œë“œë¨, ì‹¤ì œ ê²½ë¡œ ì…ë ¥ ê¶Œì¥)
CLS_MODEL_PATH = r"runs\classify\test1\weights\best.pt"    # ë¶„ë¥˜ ëª¨ë¸ (ì‹¤ì œ ê²½ë¡œ ì…ë ¥ ê¶Œì¥)

# 2. Segformer ëª¨ë¸ ê²½ë¡œ ë° ê°€ì¤‘ì¹˜
SEG_MODEL_NAME = "nvidia/mit-b0"
SEG_WEIGHT_PATH = r"runs\seg\PA\PA_MIOU.pth"  # â˜… ì‚¬ìš©ìì˜ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ê²½ë¡œ

# 3. í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œ
TEST_IMAGE_PATH = r"C:\Users\sega0\Desktop\chytonpide-ai\predict_image\test4.jpg"

# 4. ê¸°íƒ€ ì„¤ì •
SCALE_REAL_DIAMETER_MM = 16.0  # ìŠ¤í‹°ì»¤ ì‹¤ì œ ì§€ë¦„
GREEN_HSV_LOWER = [35, 40, 40]
GREEN_HSV_UPPER = [85, 255, 255]
NUM_SEG_CLASSES = 2  # 0: ë°°ê²½, 1: ì


class IntegratedBasilAnalyzer:
    """YOLOì™€ Segformerê°€ í†µí•©ëœ ë°”ì§ˆ ë¶„ì„ê¸°"""

    def __init__(self):
        logger.info("ğŸ¤– AI ëª¨ë¸ ë¡œë”© ì‹œì‘...")
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        logger.info(f"ğŸ‘‰ ì‚¬ìš© ì¥ì¹˜: {self.device}")

        try:
            # 1. YOLO ëª¨ë¸ ë¡œë”©
            self.det_model = YOLO(DET_MODEL_PATH)
            self.cls_model = YOLO(CLS_MODEL_PATH)
            logger.info("âœ… YOLO ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

            # 2. Segformer ëª¨ë¸ ë¡œë”©
            self.seg_processor = SegformerImageProcessor.from_pretrained(SEG_MODEL_NAME)
            
            id2label = {0: "background", 1: "leaf"}
            label2id = {"background": 0, "leaf": 1}
            
            self.seg_model = SegformerForSemanticSegmentation.from_pretrained(
                SEG_MODEL_NAME,
                num_labels=NUM_SEG_CLASSES,
                id2label=id2label,
                label2id=label2id,
                ignore_mismatched_sizes=True
            )

            # ê°€ì¤‘ì¹˜ ë¡œë“œ
            if os.path.exists(SEG_WEIGHT_PATH):
                checkpoint = torch.load(SEG_WEIGHT_PATH, map_location=self.device)
                state_dict = checkpoint['state_dict'] if 'state_dict' in checkpoint else checkpoint
                self.seg_model.load_state_dict(state_dict, strict=False)
                self.seg_model.to(self.device)
                self.seg_model.eval()
                logger.info("âœ… Segformer ëª¨ë¸ ë° ê°€ì¤‘ì¹˜ ë¡œë”© ì™„ë£Œ")
            else:
                logger.warning(f"âš ï¸ Segformer ê°€ì¤‘ì¹˜ íŒŒì¼ ì—†ìŒ: {SEG_WEIGHT_PATH}. ê¸°ë³¸ ê°€ì¤‘ì¹˜ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
                self.seg_model.to(self.device)

        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            raise

    def _determine_stage(self, leaf_count):
        """ì ê°œìˆ˜ì— ë”°ë¥¸ ìƒìœ¡ ë‹¨ê³„ íŒë³„"""
        if leaf_count <= 2:
            return "ğŸŒ± ë–¡ì ë‹¨ê³„", "ë–¡ìë§Œ ì¡´ì¬í•˜ê±°ë‚˜, ë³¸ì—½ì´ ë‚˜ì˜¤ê¸° ì§ì „ì…ë‹ˆë‹¤."
        elif 3 <= leaf_count <= 4:
            return "ğŸŒ¿ ë³¸ì—½ 2ë§¤", "ë³¸ì—½ì´ 1ìŒ(2ì¥) ì „ê°œëœ ìƒíƒœì…ë‹ˆë‹¤."
        elif 5 <= leaf_count <= 8:
            return "ğŸŒ¿ ë³¸ì—½ 4ë§¤ ~ 8ë§¤", "ë³¸ì—½ì´ 2ìŒì—ì„œ 4ìŒê¹Œì§€ í™œë°œíˆ ìë¼ëŠ” ì¤‘ì…ë‹ˆë‹¤."
        elif 9 <= leaf_count <= 10:
            return "ğŸŒ¿ ë³¸ì—½ 8ë§¤ ~ 10ë§¤", "ë³¸ì—½ ì„±ì¥ì´ ê±°ì˜ ì™„ë£Œë˜ì–´ ê°€ë©°, ê³§ ë¶„ì§€ê°€ ì˜ˆìƒë©ë‹ˆë‹¤."
        else:
            return "ğŸŒ³ ë¶„ì§€ ë°œìƒ", "ìì´ 10ë§¤ ì´ìƒì´ë©°, ê³ê°€ì§€(ë¶„ì§€)ê°€ ë°œë‹¬í•˜ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤."

    def _analyze_growth_stage(self, pil_image):
        """Segformerë¥¼ ì´ìš©í•œ ì ê°œìˆ˜ ë° ì„±ì¥ ë‹¨ê³„ ë¶„ì„"""
        try:
            # ë¦¬ì‚¬ì´ì§• (ëª¨ë¸ ì…ë ¥ í¬ê¸°ì— ë§ì¶¤)
            target_size = (640, 640)
            img_resized = pil_image.resize(target_size)
            
            inputs = self.seg_processor(images=img_resized, return_tensors="pt").to(self.device)

            with torch.no_grad():
                outputs = self.seg_model(**inputs)
            
            logits = outputs.logits
            # ì›ë˜ í¬ê¸°ë¡œ ë³µì›í•˜ì§€ ì•Šê³  ë¦¬ì‚¬ì´ì¦ˆëœ ìƒíƒœì—ì„œ ë§ˆìŠ¤í¬ ìƒì„± (ì—°ì‚° íš¨ìœ¨ì„±)
            upsampled_logits = torch.nn.functional.interpolate(
                logits,
                size=target_size[::-1],
                mode="bilinear",
                align_corners=False,
            )
            
            # ë§ˆìŠ¤í¬ ì¶”ì¶œ (0: ë°°ê²½, 1: ì)
            pred_mask = upsampled_logits.argmax(dim=1)[0].cpu().numpy().astype(np.uint8)
            
            # ì(1) ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ì—¬ ê°œìˆ˜ ì„¸ê¸°
            leaf_mask = (pred_mask == 1).astype(np.uint8) * 255
            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(leaf_mask, connectivity=8)
            leaf_count = num_labels - 1  # ë°°ê²½ ì œì™¸

            stage_name, message = self._determine_stage(leaf_count)
            
            return {
                "leaf_count": leaf_count,
                "stage": stage_name,
                "message": message,
                "mask": leaf_mask  # ì‹œê°í™”ë¥¼ ìœ„í•´ ë§ˆìŠ¤í¬ ë°˜í™˜
            }

        except Exception as e:
            logger.error(f"âŒ ì„±ì¥ ë‹¨ê³„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    def _calculate_pla(self, basil_crop_bgr, mm_per_pixel):
        """ê¸°ì¡´ PLA(ì—½ë©´ì ) ê³„ì‚° ë¡œì§"""
        try:
            basil_hsv = cv2.cvtColor(basil_crop_bgr, cv2.COLOR_BGR2HSV)
            lower_green = np.array(GREEN_HSV_LOWER, dtype=np.uint8)
            upper_green = np.array(GREEN_HSV_UPPER, dtype=np.uint8)
            green_mask = cv2.inRange(basil_hsv, lower_green, upper_green)
            
            kernel = np.ones((3, 3), np.uint8)
            green_mask = cv2.morphologyEx(green_mask, cv2.MORPH_OPEN, kernel)
            green_pixel_count = cv2.countNonZero(green_mask)

            area_mm2 = green_pixel_count * (mm_per_pixel ** 2)
            return {
                "pla_mm2": round(area_mm2, 2),
                "green_pixels": int(green_pixel_count),
            }
        except Exception as e:
            logger.error(f"âŒ PLA ê³„ì‚° ì˜¤ë¥˜: {e}")
            return None

    def process_file(self, image_path):
        """ë¡œì»¬ íŒŒì¼ ì²˜ë¦¬ìš© í•¨ìˆ˜"""
        if not os.path.exists(image_path):
            logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            return
        
        with open(image_path, "rb") as f:
            image_bytes = f.read()
        
        return self.process(image_bytes)

    def process(self, image_bytes):
        """ì „ì²´ ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        try:
            # 1. ì´ë¯¸ì§€ ì¤€ë¹„
            origin_img_pil = Image.open(io.BytesIO(image_bytes))
            origin_img_pil = ImageOps.exif_transpose(origin_img_pil).convert("RGB")
            origin_img_bgr = cv2.cvtColor(np.array(origin_img_pil), cv2.COLOR_RGB2BGR)

            # 2. YOLO íƒì§€ (Crop & Scale)
            results = self.det_model(origin_img_pil, conf=0.15, verbose=False)
            
            mm_per_pixel = 0.0
            basil_crop_pil = None
            basil_crop_bgr = None
            
            # --- ê²°ê³¼ íŒŒì‹± ---
            found_ids = results[0].boxes.cls.cpu().numpy().astype(int) if len(results) > 0 else []
            boxes = results[0].boxes

            # A. Scale ë§ˆì»¤ ì°¾ê¸° (ID: 1)
            for i, cls_id in enumerate(found_ids):
                if cls_id == 1:
                    box = boxes[i]
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    diameter = max(x2 - x1, y2 - y1)
                    mm_per_pixel = SCALE_REAL_DIAMETER_MM / diameter
                    logger.info(f"ğŸ“ Scale ê°ì§€ë¨: 1px = {mm_per_pixel:.4f}mm")
                    break
            
            # B. ë°”ì§ˆ ì°¾ê¸° (ID: 0)
            for i, cls_id in enumerate(found_ids):
                if cls_id == 0:
                    box = boxes[i]
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    basil_crop_bgr = origin_img_bgr[y1:y2, x1:x2]
                    basil_crop_pil = Image.fromarray(cv2.cvtColor(basil_crop_bgr, cv2.COLOR_BGR2RGB))
                    logger.info(f"ğŸŒ¿ ë°”ì§ˆ ê°ì§€ë¨: í¬ê¸° {basil_crop_pil.size}")
                    break

            if basil_crop_pil is None:
                return {"status": "error", "message": "ë°”ì§ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
            if mm_per_pixel == 0:
                logger.warning("âš ï¸ ìŠ¤ì¼€ì¼ ë§ˆì»¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì„ì˜ ê°’(1.0)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                mm_per_pixel = 0.1 # ì„ì˜ ê°’

            # 3. PLA ê³„ì‚°
            pla_result = self._calculate_pla(basil_crop_bgr, mm_per_pixel)

            # 4. ê±´ê°• ìƒíƒœ ë¶„ë¥˜ (YOLO-CLS)
            cls_results = self.cls_model(basil_crop_pil, verbose=False)[0]
            health_status = cls_results.names[cls_results.probs.top1]
            health_conf = float(cls_results.probs.top1conf) * 100

            # 5. [NEW] ì„±ì¥ ë‹¨ê³„ ë¶„ì„ (Segformer)
            # ë°”ì§ˆ ë¶€ë¶„ë§Œ ì˜ë¦° ì´ë¯¸ì§€(basil_crop_pil)ë¥¼ ë„£ì–´ì„œ ë¶„ì„ ì •í™•ë„ í–¥ìƒ
            logger.info("ğŸ” ì„±ì¥ ë‹¨ê³„ ì •ë°€ ë¶„ì„ ì¤‘ (Segformer)...")
            growth_info = self._analyze_growth_stage(basil_crop_pil)

            # 6. ê²°ê³¼ ì¢…í•© ë° ì‹œê°í™” ì €ì¥
            result_data = {
                "health": {"status": health_status, "confidence": f"{health_conf:.2f}%"},
                "pla": pla_result,
                "growth": growth_info
            }
            
            self._save_visualization(origin_img_bgr, basil_crop_bgr, growth_info)

            return {"status": "success", "data": result_data}

        except Exception as e:
            logger.error(f"ì²˜ë¦¬ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}", exc_info=True)
            return {"status": "error", "message": str(e)}

    def _save_visualization(self, original_img, crop_img, growth_info):
        """ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ (ë¡œì»¬ ì‹¤í—˜ìš©)"""
        try:
            save_path = "result_combined.jpg"
            
            # ë§ˆìŠ¤í¬ ì‹œê°í™” (Segformer ê²°ê³¼ê°€ ìˆë‹¤ë©´)
            if growth_info and growth_info['mask'] is not None:
                mask = growth_info['mask']
                # ë§ˆìŠ¤í¬ë¥¼ crop ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì§•
                mask_resized = cv2.resize(mask, (crop_img.shape[1], crop_img.shape[0]), interpolation=cv2.INTER_NEAREST)
                
                # ì´ˆë¡ìƒ‰ ì˜¤ë²„ë ˆì´
                color_mask = np.zeros_like(crop_img)
                color_mask[mask_resized == 255] = [0, 255, 0]
                overlay_crop = cv2.addWeighted(crop_img, 0.7, color_mask, 0.3, 0)
                
                # í…ìŠ¤íŠ¸ ì¶”ê°€
                txt = f"{growth_info['stage']} (Leaf: {growth_info['leaf_count']})"
                cv2.putText(overlay_crop, txt, (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
                
                cv2.imwrite("result_crop_seg.jpg", overlay_crop)
                logger.info(f"ğŸ’¾ ë¶„í•  ê²°ê³¼ ì €ì¥ë¨: result_crop_seg.jpg")

            logger.info("âœ… ë¶„ì„ ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"ì´ë¯¸ì§€ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

# ==========================================
# ì‹¤í–‰ ë¶€ (Main)
# ==========================================
if __name__ == "__main__":
    # ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    analyzer = IntegratedBasilAnalyzer()
    
    # ë¡œì»¬ íŒŒì¼ë¡œ í…ŒìŠ¤íŠ¸
    print("\n" + "="*50)
    print(f"ğŸš€ ë¶„ì„ ì‹œì‘: {TEST_IMAGE_PATH}")
    print("="*50)
    
    result = analyzer.process_file(TEST_IMAGE_PATH)
    
    import json
    if result and result['status'] == 'success':
        data = result['data']
        print("\nğŸ“Š [ìµœì¢… ë¶„ì„ ê²°ê³¼]")
        print(f"1. ê±´ê°• ìƒíƒœ : {data['health']['status']} ({data['health']['confidence']})")
        print(f"2. ì—½ë©´ì (PLA): {data['pla']['pla_mm2']} mmÂ²")
        
        if data['growth']:
            print(f"3. ì ê°œìˆ˜   : {data['growth']['leaf_count']} ì¥")
            print(f"4. ì„±ì¥ ë‹¨ê³„ : {data['growth']['stage']}")
            print(f"5. ìƒì„¸ ì½”ë©˜íŠ¸: {data['growth']['message']}")
        else:
            print("3. ì„±ì¥ ë‹¨ê³„ : ë¶„ì„ ì‹¤íŒ¨")
    else:
        print("âŒ ë¶„ì„ ì‹¤íŒ¨:", result)